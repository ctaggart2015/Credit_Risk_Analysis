# Credit_Risk_Analysis
Machine Learning and Credit Risk
## Overview of the analysis:
In this challenge we are asked to use different methods to test and evaluate the data. Using different models some meathods such as BalancedRandomForestClassifier, EasyEnsembleClassifier, and SMOTE algorithms to test the data.
## Results:
### Naive Random Oversampling:
<img width="856" alt="Screen Shot 2022-08-13 at 1 33 22 PM" src="https://user-images.githubusercontent.com/99035696/184504726-8287631f-4fca-41a0-8444-d57fee0c2f47.png">
balanced accuracy: 0.6876489392618425
precision: The precision is low for High-risk and is high for Low-risk.
recall: High risk = .57 , Low risk = .69
### SMOTE Oversampling:
<img width="856" alt="Screen Shot 2022-08-13 at 1 39 11 PM" src="https://user-images.githubusercontent.com/99035696/184504877-018485e6-2cb8-4a84-bb0f-0ea1e857b422.png">

balanced accuracy: 0.6314677834584286
precision: The precision is low for High-risk and is high for Low-risk.
recall:High risk = . , Low risk = 
### Undersampling:

balanced accuracy: 
precision: The precision is  for High-risk and is  for Low-risk.
recall:High risk = . , Low risk = 
### Combination Under-Over Sampling:

balanced accuracy: 
precision: The precision is  for High-risk and is  for Low-risk.
recall:High risk = . , Low risk = 
### Balanced Random Forest Classifier:

balanced accuracy: 
precision: The precision is  for High-risk and is  for Low-risk.
recall:High risk = . , Low risk = 
### Easy Ensemble AdaBoost Classifier:

balanced accuracy: 
precision: The precision is  for High-risk and is  for Low-risk.
recall:High risk = . , Low risk = 
## Summary: 

